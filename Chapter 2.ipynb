{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: A/B Testing: Evaluating a Change to the System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi']= 300\n",
    "\n",
    "clr1 = \"#333333\"\n",
    "clr2 = \"#777777\"\n",
    "clr3 = \"#AAAAAA\"\n",
    "clr4 = \"#DDDDDD\"\n",
    "clrs = [clr1, clr2, clr3, clr4]\n",
    "arrow_props = {'width':1, 'color': clr1,\n",
    "                'headwidth': 5, 'headlength': 7}\n",
    "\n",
    "\n",
    "fig_dir = \"/Users/dsweet2/Desktop/Tuning Up/Chapter 2/\"\n",
    "def save_fig_named(name):\n",
    "    plt.tight_layout()\n",
    "    for ext in [\"eps\", \"png\"]:\n",
    "        plt.savefig(f\"{name}.{ext}\")\n",
    "        \n",
    "def save_fig(fig_num):\n",
    "    save_fig_named(f\"{fig_dir}/CH02_F{fig_num:02d}_sweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizonal_line(y0):\n",
    "    c = plt.axis()\n",
    "    plt.autoscale(False)\n",
    "    plt.plot([c[0], c[1]], [y0, y0], '--', linewidth=1, color=clr3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\tDesign I: Randomize to remove measurement bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that Python converts between booleans and floats like this:\n",
    "print (float(True), float(False))\n",
    "print (bool(0), bool(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1\tA problematic design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(strategy_A, server_1):\n",
    "    return 10 + float(strategy_A) - 2*float(server_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost(strategy_A=True, server_1=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biased_experiment():\n",
    "    cost_A = cost(strategy_A=True, server_1=True)\n",
    "    cost_B = cost(strategy_A=False, server_1=False)\n",
    "\n",
    "    return cost_B - cost_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2\tAn unbiased design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unbiased_experiment():\n",
    "    cost_A_1 = cost(strategy_A=True, server_1=True)\n",
    "    cost_A_2 = cost(strategy_A=True, server_1=False)\n",
    "    cost_B_1 = cost(strategy_A=False, server_1=False)\n",
    "    cost_B_2 = cost(strategy_A=False, server_1=True)    \n",
    "    cost_A = (cost_A_1 + cost_A_2)/2\n",
    "    cost_B = (cost_B_1 + cost_B_2)/2\n",
    "    \n",
    "    return cost_B - cost_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbiased_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_order_is_for_ABC():\n",
    "    return bool(np.random.randint(2))\n",
    "def randomized_experiment():\n",
    "    cost_A = cost(strategy_A=True, server_1=customer_order_is_for_ABC())\n",
    "    cost_B = cost(strategy_A=False, server_1=customer_order_is_for_ABC())\n",
    "            \n",
    "    return cost_B - cost_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "print (randomized_experiment())\n",
    "print (randomized_experiment())\n",
    "print (randomized_experiment())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2\tDesign II: Replicate to reduce variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1\tReplication reduces variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice([-1,1], size=(10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_complex(strategy_A, num_nuisance_factors):\n",
    "    NF = np.random.choice([-1,1], size=(num_nuisance_factors,))\n",
    "    return float(strategy_A) + NF.sum()/20\n",
    "\n",
    "def randomized_experiment_complex(num_nuisance_factors):\n",
    "    cost_A = cost_complex(True, num_nuisance_factors)\n",
    "    cost_B = cost_complex(False, num_nuisance_factors)\n",
    "            \n",
    "    return cost_B - cost_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "print (randomized_experiment_complex(num_nuisance_factors=100))\n",
    "print (randomized_experiment_complex(num_nuisance_factors=100))\n",
    "print (randomized_experiment_complex(num_nuisance_factors=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17);\n",
    "data_rec_10000 = np.array([\n",
    "    randomized_experiment_complex(num_nuisance_factors=100)\n",
    "                           for _ in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (data_rec_10000.mean() - 2*data_rec_10000.std())\n",
    "print (data_rec_10000.mean() + 2*data_rec_10000.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_rec_10000, 15, color=clr1);\n",
    "plt.xlabel(r'$cost_B - cost_A$')\n",
    "plt.ylabel('count');\n",
    "save_fig(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_measurement(num_measurements):\n",
    "    measurements = [randomized_experiment_complex(num_nuisance_factors=100)\n",
    "                    for _ in range(num_measurements)]\n",
    "    return np.array(measurements).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17);\n",
    "print (aggregate_measurement(10))\n",
    "print (aggregate_measurement(10))\n",
    "print (aggregate_measurement(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_mean(data, num_measurements):\n",
    "    # Compute means by resampling from data rather than generating new data.\n",
    "    # This is done here just to speed up figure generation in this notebook. \n",
    "    # It saves the time that would be required to\n",
    "    #  generate new data on each call to this function.\n",
    "    i = np.random.randint(data.shape[0], size=(num_measurements,))\n",
    "    return data[i].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17);\n",
    "data_10 = np.array([bootstrap_mean(data_rec_10000, 10) for _ in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_rec_10000,15,color=clr1);\n",
    "plt.hist(data_10,15,color=clr2);\n",
    "plt.xlabel(r'$cost_B - cost_A$')\n",
    "plt.ylabel('count');\n",
    "plt.legend(['single measurement', 'average of\\n10 measurements'], fontsize=8);\n",
    "save_fig(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17);\n",
    "data_100 = np.array([bootstrap_mean(data_rec_10000, 100) for _ in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_rec_10000,15,color=clr1);\n",
    "plt.hist(data_10,15,color=clr2);\n",
    "plt.hist(data_100,15,color=\"#BBBBBB\");\n",
    "plt.xlabel(r'$cost_B - cost_A$')\n",
    "plt.ylabel('count');\n",
    "plt.legend(['single measurement', 'average of\\n10 measurements',\n",
    "           'average of\\n100 measurements'], fontsize=8);\n",
    "save_fig(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2\tQuantify variation with standard error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESTIMATE SD(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_SD1():\n",
    "    num_measurements = 1000\n",
    "    measurements_A = [cost_complex(strategy_A=True,\n",
    "                            num_nuisance_factors=100)\n",
    "                    for _ in range(num_measurements)]\n",
    "\n",
    "    std_A = np.array(measurements_A).std()\n",
    "    return np.sqrt(2)*std_A\n",
    "\n",
    "np.random.seed(17); calc_SD1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3\tDesign III: Determine the number of individual measurements to take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_vs_N(data_rec_10000, expectation, hline=None, histogram=True, N_range=(1, 10000), k=None):\n",
    "    N = np.arange(N_range[0], N_range[1])\n",
    "    if histogram:\n",
    "        data = []\n",
    "        for n in N:\n",
    "            for _ in range(10):\n",
    "                m = bootstrap_mean(data_rec_10000, n)\n",
    "                data.append( (n,m) )\n",
    "        data = np.array(data)\n",
    "        plt.plot(data[:,0], expectation + data[:,1] + 1, '.', markersize=1, color=clr3)\n",
    "        \n",
    "    sd = data_rec_10000.std()\n",
    "    if N_range[1]-N_range[0] <= 100:\n",
    "        fmt = \".--\"\n",
    "        fmtk = \":\"\n",
    "    else:\n",
    "        fmt = \"--\"\n",
    "        fmtk = \":\"\n",
    "        \n",
    "    if k is None:\n",
    "        clr = clr1\n",
    "    else:\n",
    "        clr = clr2\n",
    "    plt.plot(N, expectation + sd/np.sqrt(N), fmt, color=clr, label='-PS + S.E.')\n",
    "    plt.plot(N, expectation - sd/np.sqrt(N), fmt, color=clr)\n",
    "    if k is not None:\n",
    "        sk = f\"{k:.2f}\"[1:]\n",
    "        plt.plot(N, expectation + k*sd/np.sqrt(N), fmtk, color=clr1, label=f'-PS + {sk}xS.E.')\n",
    "        plt.plot(N, expectation - k*sd/np.sqrt(N), fmtk, color=clr1)\n",
    "        plt.legend()\n",
    "\n",
    "\n",
    "    plt.xlabel('number of individual measurements, N')\n",
    "    plt.ylabel('$cost_B - cost_A$')\n",
    "    \n",
    "    if histogram:\n",
    "        plt.legend(['aggregate measurement', 'standard error (S.E.)'], fontsize=8,\n",
    "                  loc = 'lower right');\n",
    "\n",
    "    if hline is not None:\n",
    "        horizonal_line(hline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "se_vs_N(data_rec_10000, expectation=-1)\n",
    "save_fig(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1\tMinimize measurement costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "se_vs_N(data_rec_10000, expectation=-1, hline=0)\n",
    "\n",
    "plt.annotate(\"$cost_B - cost_A > 0$\", xy=[100, .07],\n",
    "             xytext=[2000, -.6],\n",
    "              arrowprops=arrow_props\n",
    "            )\n",
    "\n",
    "\n",
    "save_fig(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2\tLimiting incorrect rejection (false negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS = .3\n",
    "se_vs_N(data_rec_10000, expectation=-PS, hline=0, histogram=False)\n",
    "save_fig(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_vs_N(data_rec_10000, expectation=-PS, hline=0, histogram=False,\n",
    "        N_range=(1,10))\n",
    "save_fig(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS = .3\n",
    "np.random.seed(17)\n",
    "SD1 = calc_SD1()\n",
    "N = (SD1/PS)**2\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_vs_N(data_rec_10000, expectation=-PS, hline=0, histogram=False,\n",
    "        N_range=(1,10), k=.84)\n",
    "save_fig(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3\tCalculate the false-negatives threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1: UNDERSTAND THE  DISTRIBUTION OF AGGREGATE MEASUREMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 0, 0, .5, .5, 1])\n",
    "np.random.seed(17)\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "axs=axs.flatten()\n",
    "for i, N in enumerate([1, 3, 10, 30, 100, 300]):\n",
    "    axs[i].set(adjustable='datalim')#, aspect='equal')\n",
    "    axs[i].axis('square')\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "    y = [np.random.choice(x, N).mean() for _ in range(1000)]\n",
    "    n, bins = np.histogram(y,10)\n",
    "    n = n/n.max()\n",
    "    # axs[i].axis([-.1, 1.1, 0, 1.1])\n",
    "    axs[i].axis([-.1, 1.1, 0, 1.1])\n",
    "    axs[i].bar(bins[:-1], n, width=.03, color=clr1)\n",
    "    axs[i].set_title(f\"N={N}\", fontsize=7);\n",
    "    \n",
    "save_fig_named(f\"{fig_dir}/CH02_Fsidebar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2: SIMULATE AGGREGATE MEASUREMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.random.normal(size=(10000,)), 25, color=clr1);\n",
    "plt.hist(4 + .5*np.random.normal(size=(10000,)), 25, color=clr2);\n",
    "c = plt.axis()\n",
    "plt.axis([c[0], c[1], 0, 1700])\n",
    "plt.legend(['np.random.normal(size=(10000,))', '4 + .5*np.random.normal(size=(10000,))'], loc='upper left');\n",
    "save_fig(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_measurement_model(N):\n",
    "    PS = .3\n",
    "    SD1 = .707\n",
    "    SE = SD1/np.sqrt(N)\n",
    "    return -PS + SE*np.random.normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "print (aggregate_measurement_model(N=6))\n",
    "print (aggregate_measurement_model(N=6))\n",
    "print (aggregate_measurement_model(N=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_false_negative(N):\n",
    "    samples = np.array([aggregate_measurement_model(N)\n",
    "                        for _ in range(10000)])\n",
    "    return len(np.where(samples > 0)[0]) / len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "probability_false_negative(N=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "probability_false_negative(N=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_above_k(mean, standard_deviation, k):\n",
    "    samples = mean + standard_deviation*np.random.normal(size=(100000,))\n",
    "    threshold = mean + k*standard_deviation\n",
    "    return len(np.where(samples > threshold)[0]) / len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_above_k(-3, .707, .84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_above_k(k):\n",
    "    samples = np.random.normal(size=(100000,))\n",
    "    return len(np.where(samples > k)[0]) / len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_above_k(.84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 3: FIND THE THRESHOLD THAT YIELDS 20% FALSE NEGATIVES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_fn_fp():\n",
    "    SD1 = .707\n",
    "    PS = .3\n",
    "    data = []\n",
    "    thresh = None\n",
    "    best_N = None\n",
    "    for N in range(1,100):\n",
    "        SE = SD1 / np.sqrt(N)\n",
    "        upper_fp_alpha = 0 + 1.96*SE\n",
    "        lower_fp_alpha = 0 - 1.96*SE\n",
    "        upper_fn_beta = -PS + .84*SE\n",
    "        lower_fn_beta = -PS - .84*SE\n",
    "        if thresh is None and upper_fn_beta <= lower_fp_alpha:\n",
    "            thresh = (upper_fn_beta + lower_fp_alpha) / 2\n",
    "            best_N = N\n",
    "        data.append( (N, upper_fp_alpha, lower_fp_alpha, upper_fn_beta, lower_fn_beta) )\n",
    "    return np.array(data), thresh, best_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, thresh, best_N = overlap_fn_fp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS = .3\n",
    "SD1 = .707\n",
    "N = (.84 * SD1 / PS)**2\n",
    "print (N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(data[:,0], data[:,3], data[:,4], color=clr3, alpha=.75, linewidth=1)\n",
    "\n",
    "\n",
    "plt.xlabel('number of measurements, N')\n",
    "plt.ylabel('$cost_B - cost_A$')\n",
    "plt.legend([r'$-.3 \\pm .84 S.E$'])\n",
    "horizonal_line(0)\n",
    "save_fig(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4\tLimiting incorrect acceptance (false positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(data[:,0], data[:,1], data[:,2], color=clr2, alpha=.75, linewidth=1)\n",
    "\n",
    "\n",
    "plt.xlabel('number of measurements, N')\n",
    "plt.ylabel('$cost_B - cost_A$')\n",
    "plt.legend([r'$0 \\pm 1.96 S.E$'])\n",
    "\n",
    "save_fig(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5\tLimiting false negatives and false positives simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (thresh, best_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, thresh, best_N = overlap_fn_fp()\n",
    "plt.fill_between(data[:,0], data[:,3], data[:,4], color=clr3, alpha=.75, linewidth=1)\n",
    "plt.fill_between(data[:,0], data[:,1], data[:,2], color=clr2, alpha=.75, linewidth=1)\n",
    "\n",
    "\n",
    "circle = mpl.patches.Ellipse( (best_N, thresh), .2*25, .2, color=clr1, fill=False)#, transform=plt.gca().transAxes)\n",
    "plt.gcf().gca().add_artist(circle)\n",
    "\n",
    "plt.xlabel('number of measurements, N')\n",
    "plt.ylabel('$cost_B - cost_A$')\n",
    "plt.legend([r'$-.3 \\pm .84 S.E$', r'$0 \\pm 1.96 S.E$'],\n",
    "           fontsize=8,\n",
    "          loc = 'lower right');\n",
    "\n",
    "save_fig(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4\tRun and analyze the A/B test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1\tRun a small-sized A/A test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2.1\n",
    "alpha = .05\n",
    "table = []\n",
    "for N_small in [10, 30, 100, 300, 1000]:\n",
    "    k = scipy.stats.t.ppf(1-alpha/2, df=N_small)\n",
    "    table.append( (N_small, k) )\n",
    "table = np.array(table)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .05\n",
    "data = []\n",
    "for N_small in np.arange(10,1000,10):\n",
    "    k = scipy.stats.t.ppf(1-alpha/2, df=N_small)\n",
    "    data.append( (N_small, k) )\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[:,0], data[:,1], '-', color=clr1);\n",
    "plt.plot(table[:,0], table[:,1], '.', color=clr1)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('$N_{small}$')\n",
    "# plt.annotate(\"1.96\", xy=[0, 1.96])\n",
    "horizonal_line(1.96)\n",
    "save_fig(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2\tRun a small-sized A/B test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3\tRun and analyze the full-sized A/B test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4\tEarly stopping produces invalid conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_stat_vs_n():\n",
    "    measurements = np.array([])\n",
    "    t_stat = []\n",
    "    threshold = []\n",
    "    alpha = .05\n",
    "    num_individual_measurements = 100\n",
    "    for n in range(1, num_individual_measurements):\n",
    "        measurements = np.append(measurements, np.random.normal())\n",
    "        if n > 1:\n",
    "            mu = measurements[:n].mean()\n",
    "            sd = measurements[:n].std()\n",
    "            t = np.sqrt(n) * mu / sd\n",
    "        else:\n",
    "            t = np.nan\n",
    "        t_stat.append(t)\n",
    "        threshold.append(scipy.stats.t.ppf(1-alpha/2, df=n))\n",
    "    t_stat = np.array(t_stat)\n",
    "    threshold = np.array(threshold)\n",
    "    return t_stat, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 179\n",
    "np.random.seed(seed)\n",
    "\n",
    "t_stat, threshold = t_stat_vs_n()\n",
    "\n",
    "plt.plot(threshold, '--k', color=clr1)\n",
    "plt.plot(t_stat, color=clr2, linewidth=1);\n",
    "plt.plot(-threshold, '--k', color=clr1)\n",
    "plt.xlabel('n, index to individual measurement')\n",
    "plt.legend(['threshold, k', 't statistic'])\n",
    "\n",
    "i = np.where(t_stat > threshold)[0]\n",
    "print (i, t_stat[-1] > threshold[-1])\n",
    "\n",
    "save_fig(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_positive_rates():\n",
    "    num_ab_tests = 10000\n",
    "    fp_at_end = 0\n",
    "    fp_early_stopping = 0\n",
    "    for _ in range(num_ab_tests):\n",
    "        t_stat, threshold = t_stat_vs_n() \n",
    "        if abs(t_stat[-1]) > threshold[-1]:\n",
    "            fp_at_end += 1\n",
    "        i = np.where(abs(t_stat[1:]) > threshold[1:])[0]\n",
    "        if len(i) > 0:\n",
    "            fp_early_stopping += 1\n",
    "    return fp_at_end / num_ab_tests, fp_early_stopping / num_ab_tests\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17); false_positive_rates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster verions of t_stat_vs_sample() and false_positive_rates() used to\n",
    "#  generate data for Figure 2.19.  The original versions were easier to use for\n",
    "#  teaching, but too slow to generate the figure in a reasonable amount of time.\n",
    "def t_stat_vs_sample_fast(N):\n",
    "    measurements = np.random.normal(size=(N-1,))\n",
    "    N = np.arange(2, N+1)\n",
    "    sx = np.cumsum(measurements)\n",
    "    sxx = np.cumsum(measurements**2)\n",
    "    mu = sx/N\n",
    "    sd = np.sqrt(sxx/N - mu**2)\n",
    "    t_stats = np.sqrt(N) * mu/sd\n",
    "    return t_stats\n",
    "\n",
    "def false_positive_rates_fast(N):\n",
    "    num_ab_tests = 10000\n",
    "    fp_at_end = 0\n",
    "    fp_early_stopping = 0\n",
    "    for _ in range(num_ab_tests):\n",
    "        t_stat = t_stat_vs_sample_fast(N)    \n",
    "        if abs(t_stat[-1]) > 1.96:\n",
    "            fp_at_end += 1\n",
    "        i = np.where(abs(t_stat) > 1.96)[0]\n",
    "        if len(i) > 0:\n",
    "            fp_early_stopping += 1\n",
    "    return fp_at_end / num_ab_tests, fp_early_stopping / num_ab_tests\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "false_positive_rates_fast(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17)\n",
    "fpr = []\n",
    "for N in [10, 30, 100, 300, 1000, 3000, int(1e4), int(3e4), int(1e5)]:\n",
    "    fp_N = false_positive_rates_fast(N)[1]\n",
    "    print (N, fp_N)\n",
    "    fpr.append( (N, fp_N)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = np.array(fpr)\n",
    "plt.semilogx(fpr[:,0], fpr[:,1], '.--', color=clr1);\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('false positive rate')\n",
    "save_fig(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
